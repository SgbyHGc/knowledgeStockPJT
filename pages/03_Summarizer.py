# -*- coding: utf-8 -*-

import streamlit as st
import requests
import time
import re
from bs4 import BeautifulSoup
import google.generativeai as genai


def url_list_from_txt(uploaded_file):
  try:
    urls = uploaded_file.getvalue().decode('utf-8').splitlines()
    return urls
  except UnicodeDecodeError:
    st.error("ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—ã‚³ãƒ¼ãƒ‰ãŒUTF-8ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    return []
  
def get_text_by_class(url, class_name):
  try:
    response = requests.get(url)
    response.raise_for_status()
    soup = BeautifulSoup(response.content, 'html.parser')
    target_divs = soup.find_all('div', class_=class_name)
    if target_divs:
      extracted_text = ''.join([div.text.strip() for div in target_divs])
      extracted_text = re.sub(r"\n+", "\n", extracted_text)
      return extracted_text
    else:
      return None
  except requests.exceptions.RequestException as e:
    print(f"Failed to fetch the webpage: {e}")
    return None
  except Exception as e:
    print(f"An error occurred: {e}")
    return None
  
def get_title_from_url(url):
  """
  Fetches the title of a web page given its URL.

  Args:
    url: The URL of the web page.

  Returns:
    The title of the web page (str).
  """
  try:
    response = requests.get(url)
    response.raise_for_status()  # Raise an exception for error status codes
    soup = BeautifulSoup(response.content, "html.parser")
    title = soup.find("title").text
    return title
  except requests.exceptions.RequestException as e:
    print(f"Failed to fetch the page: {e}")
    return None
  except Exception as e:
    print(f"Failed to extract the title: {e}")
    return None

def gemini(extacted_text, api_key):
  template = """
  ## Persona
  ã‚ãªãŸã¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è³‡æ–™ä½œæˆã®ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆã§ã™ã€‚
  ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å†…å®¹ã‚’èª­ã¿å–ã‚Šã€ç®‡æ¡æ›¸ãã§è¦ç‚¹ã‚’è©³ç´°ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

  ## Context
  å–¶æ¥­éƒ¨å“¡ãŒé¡§å®¢å‘ã‘ã®ææ¡ˆè³‡æ–™ä½œæˆã‚„é¡§å®¢ã‹ã‚‰ã®è³ªå•ã‚’å—ã‘ãŸéš›ã«å‚è€ƒã¨ãªã‚‹è³‡æ–™ãŒå¤šãã‚ã‚Šã¾ã™ãŒã€
  ä¸€ã¤ä¸€ã¤ã‚’æŠŠæ¡ã™ã‚‹ã“ã¨ã¯å›°é›£ãªãŸã‚å…¨éƒ¨èª­ã¾ãªãã¦ã‚‚è¦ç‚¹ã‚’ã¤ã‹ã‚ã‚‹ã‚ˆã†ã«ã¾ã¨ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

  ## ãƒ†ã‚­ã‚¹ãƒˆãƒ¼ã‚¿
  <text_data>

  ## Task
  - æ–‡ç« ã®ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’è¦ç‚¹ã¨ã—ã¦è¦‹é€ƒã•ãªã„ã‚ˆã†æ³¨æ„ã—ã¦3~5å€‹ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
  - è¦ç‚¹ã‚’å‡ºåŠ›ã™ã‚‹éš›ã¯ç°¡æ½”ã«æ—¥æœ¬èªã§500æ–‡å­—ä»¥å†…ã«åã‚ã¦ãã ã•ã„ã€‚
  - æ¤œç´¢ç”¨ã®ã‚¿ã‚°ã¨ã—ã¦ã€åˆ©ç”¨è€…ãŒä½¿ãˆãã†ãªæ¤œç´¢ç”¨ã®ã‚¿ã‚°ã‚‚å½“ã¦ã¯ã¾ã‚Šãã†ãªã‚‚ã®ã‚’ä½œã£ã¦ãã ã•ã„ã€‚
  - æ›¸å¼ã‚’çµ±ä¸€ã—ã¦ãã ã•ã„ã€‚
  - ã»ã©ã»ã©ã®é•·ã•ã§æ”¹è¡Œã‚’ã—ã¦ãã ã•ã„ã€‚
  - å‡ºåŠ›ã‚’ä¸€ã¾ã¨ã¾ã‚Šã¨èªè­˜ã§ãã‚‹ã‚ˆã†ã«ç®‡æ¡æ›¸ãã§ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã—ã¦ãã ã•ã„ã€‚
  - é …ç›®é–“ã«ç„¡ç”¨ãªæ”¹è¡Œã‚’å…¥ã‚Œãªã„ã§ãã ã•ã„ã€‚

  ## Format
  ## è¦ç‚¹
  1. è¦ç‚¹1
  ## æ¤œç´¢ç”¨ã‚¿ã‚°:
  ã‚¿ã‚°1,ã‚¿ã‚°2

  ## ä¾‹
  ## è¦ç‚¹
  1. åºƒå‘ŠåŠ¹æœã®å¤šè§’çš„ãªã€Œæ¸¬å®šã€ã®å¿…è¦æ€§: è¿‘å¹´ã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·å¼·åŒ–ã«ã‚ˆã‚Šã€å¾“æ¥ã®ãƒ‡ãƒ¼ã‚¿è¨ˆæ¸¬ãŒå›°é›£ã«ã€‚ãƒãƒ³ãƒ€ã‚¤ãƒŠãƒ ã‚³ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆ(BNEI)ã§ã¯ã€MMMã‚„CausalImpactãªã©ã®æ‰‹æ³•ã‚’ç”¨ã„ã€å¤šè§’çš„ã«åºƒå‘ŠåŠ¹æœã‚’æ¸¬å®šã™ã‚‹ã“ã¨ã§ã€å¤‰åŒ–ã¸ã®å¯¾å¿œã¨æ„æ€æ±ºå®šã‚’å¯èƒ½ã«ã—ã¦ã„ã‚‹ã€‚
  1. MMMã«ã‚ˆã‚‹åŒ…æ‹¬çš„ãªåŠ¹æœæ¸¬å®š: ç‹¬è‡ªã®MMMã‚’é–‹ç™ºã—ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ»ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã‚’å«ã‚€å¤šæ§˜ãªãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³æ–½ç­–ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ•°ã¸ã®è²¢çŒ®åº¦ã‚’åˆ†æã€‚æ–½ç­–é–“ç›¸äº’ä½œç”¨ã‚‚è€ƒæ…®ã—ãŸäºˆç®—é…åˆ†ã‚„ã€äºˆæ¸¬å€¤ã¨å®Ÿæ¸¬å€¤ã®èª¤å·®ãŒå°‘ãªã„é«˜ç²¾åº¦ãªãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã‚’å®Ÿç¾ã€‚
  1. CausalImpactã«ã‚ˆã‚‹èªçŸ¥æ–½ç­–ã®åŠ¹æœæ¤œè¨¼: å¾“æ¥ã€æ‡ç–‘çš„ãªè¦‹æ–¹ãŒã‚ã£ãŸèªçŸ¥æ–½ç­–ã®åŠ¹æœã‚’ã€CausalImpactã‚’ç”¨ã„ãŸåˆ†æã«ã‚ˆã‚Šå®šé‡åŒ–ã€‚YouTubeåºƒå‘Šé…ä¿¡ã«ã‚ˆã‚‹ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ•°ã®ç´”å¢—ã‚„ã€ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒšãƒ¼ã‚¸ã¸ã®é·ç§»ç‡å‘ä¸Šã‚’å®Ÿè¨¼ã—ã€èªçŸ¥æ–½ç­–ã®è²¢çŒ®åº¦ã‚’æ˜ç¢ºåŒ–ã€‚
  1. iOSã‚¢ãƒ—ãƒªåºƒå‘Šã«ãŠã‘ã‚‹ã€Œæ¨å®šROASã€ã®æ´»ç”¨: ATTå°å…¥ã«ã‚ˆã‚‹iOSã‚¢ãƒ—ãƒªåºƒå‘Šã®åŠ¹æœæ¸¬å®šã®èª²é¡Œã«å¯¾ã—ã€ã€Œæ¨å®šROASã€ã‚’é–‹ç™ºãƒ»é‹ç”¨ã€‚å¾“æ¥ã®ROASã«è¿‘ã„æ•°å€¤ã‚’ç®—å‡ºã™ã‚‹ã“ã¨ã§ã€iOSã‚¢ãƒ—ãƒªã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®å‡ºç¨¿ã‚¿ã‚¤ãƒˆãƒ«æ•°å¢—åŠ ã¨ROASç›®æ¨™é”æˆã‚’å®Ÿç¾ã€‚
  1. å¤šè§’çš„ãªæ¤œè¨¼ã«ã‚ˆã‚‹çµ„ç¹”é¢¨åœŸã®é†¸æˆ: MMMã€CausalImpactã€ã€Œæ¨å®šROASã€ã¨ã„ã£ãŸå¤šè§’çš„ãªæ¤œè¨¼ä½“åˆ¶ã®æ§‹ç¯‰ã«ã‚ˆã‚Šã€ç¤¾å†…ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸæ„æ€æ±ºå®šã‚’ä¿ƒé€²ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³ãªãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã¸ã®æ„è­˜æ”¹é©ã‚’æ¨é€²ã—ã€çµ„ç¹”å…¨ä½“ã®ã€Œæ¸¬å®šã€ã«å¯¾ã™ã‚‹æ„è­˜å‘ä¸Šã‚’å®Ÿç¾ã€‚
  ## æ¤œç´¢ç”¨ã‚¿ã‚°: åºƒå‘ŠåŠ¹æœæ¸¬å®š, MMM, CausalImpact, æ¨å®šROAS, ã‚¢ãƒ—ãƒªãƒ“ã‚¸ãƒã‚¹, ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·, ATT, ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³, ãƒãƒ³ãƒ€ã‚¤ãƒŠãƒ ã‚³ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆ
  """

  genai.configure(api_key=api_key)
  prompt = template.replace("<text_data>", "\n".join(extracted_text))
  model = genai.GenerativeModel('gemini-1.5-flash')
  response = model.generate_content(
      prompt,
      generation_config={
          "temperature": 0.7,
          "max_output_tokens": 100000,
      },
      request_options={
          "timeout": 60
      }
  )
  time.sleep(2)
  return response.text

def add_info(summary, title, url):
  summary = f"# ã‚¿ã‚¤ãƒˆãƒ«: {title}\n## URL: {url}\n{summary.strip()}\n---"
  print(summary)
  return summary

# Streamlitã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®š
st.title("ã‚µãƒãƒªãƒ¼ã®å‡ºåŠ› ğŸ“š")

st.markdown('---')
st.markdown(
"""
URLã®ãƒªã‚¹ãƒˆ(txtãƒ•ã‚¡ã‚¤ãƒ«)ã«é †ç•ªã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã€æŒ‡å®šã—ãŸClass Nameã®ç®‡æ‰€ã‚’æŠœç²‹ã—ã¦Geminiã§è¦ç´„ã—ãŸçµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ã¾ã¨ã‚ã¾ã™ã€‚
å€‹ã€…ã®URLã¯æ”¹è¡Œã§åŒºåˆ‡ã‚‰ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
""")
st.markdown('---')

# URLã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å…¥åŠ›
uploaded_file = st.file_uploader("txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", type='txt')
class_name = st.text_input("URLã®ãƒšãƒ¼ã‚¸ã«å…±é€šã™ã‚‹ã€æŠ½å‡ºã—ãŸã„éƒ¨åˆ†ã®class nameã‚’æŒ‡å®šã—ã¦ãã ã•ã„", value=' page-content--detail')
api_key = st.text_input("Geminiã®API Keyã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
summarized_text = []

# æ¤œç´¢ãƒœã‚¿ãƒ³
if st.button("Summarize"):
  if uploaded_file is not None and class_name and api_key:
    urls = url_list_from_txt(uploaded_file)
    for url in urls:
      extracted_text = get_text_by_class(url, class_name)
      st.write(extracted_text)
      if extracted_text is not None:
        title = get_title_from_url(url)
        summary = gemini(extracted_text, api_key)
        summary = add_info(summary, title, url)
        summarized_text.append(summary)
        st.markdown(summary)
      continue
    txt_data = "\n".join(summarized_text)
    st.download_button(
      label="Download txt file",
      data=txt_data,
      file_name="summarized.txt",
      mime="text/plain",
      )
  else:
    st.warning("ãƒ•ã‚©ãƒ¼ãƒ ã‚’å…¨ã¦å…¥åŠ›ã—ã¦ãã ã•ã„")